---
layout: post
title: "迟到的年度总结"
published: true
---

- [游玩](#游玩)
  - [东京都内](#东京都内)
  - [东京都外](#东京都外)
- [上课](#上课)
  - [Coursera](#coursera)
  - [Open Course](#open-course)

这是一个迟到的年度总结，敦促一下今年要多加努力，也争取往后每年都能像今年一样好好记录一下！

# 游玩

去年主要都是在东京周边玩，但尽管如此还是很多地方没有去过，以下是一些不完全统计…

## 东京都内
  - Shibuya Sky
  - Disneyland land
  - 东京国立博物館
  - 新宿御苑
  - 学生票去听了东京交响乐团[第971回オーチャード定期演奏会](https://www.tpo.or.jp/en/concert/20220612-01.php)
  - CM100（第一日）+ CM101（一二日）
  - 旅馆
    - [ホテルかずさや](https://www.jalan.net/yad361698/)
    - [ラビスタ東京ベイ（共立リゾート）](https://www.jalan.net/yad307416/)

## 东京都外
  - 秩父
    - 蹭优惠活动，住了[ミッションヒルズ迎賓館](https://travel.yahoo.co.jp/00030436/)，这家条件很好，尤其是人好
    - 顺带去了[秋川渓谷](https://www.city.akiruno.tokyo.jp/0000001850.html)
    - 長瀞那边逛了一圈，打卡了摇曳露营的几个地点
  - 伊豆
    - [水のみち・風のみち　湯ヶ島　たつた](https://www.jalan.net/yad338409/)
    - [修禅寺](https://kanko.city.izu.shizuoka.jp/form1.html?pid=2375)
    - 修善寺梅林
  - 茨城（蹭了最喜欢的万学长的车，激情首都高🤤）
    - [国営ひたち海浜公園](https://hitachikaihin.jp/)
    - [千波湖](https://www.ibarakiguide.jp/db-kanko/senbalake.html)
  - 高尾山
    - 爬的是[6号路](https://mttakaomagazine.com/trails/6th)！

# 上课

去年上了不少的课，收获不小。不仅如此，上课让我英文水平得到了提高。我不再惧怕看英文的东西了，也养成了任何资源首先从英文世界获取的好习惯。

## Coursera

我花了很多很多的时间在Coursera上面。Coursera这个平台其实对萌新非常的友好，课程难度适中、课程视频长度适中，也有健全的评分系统能及时获得反馈。

### [Algorithms, Part I](https://www.coursera.org/learn/algorithms-part1) (2022年初)

2021年年末的时候我决心开始“刷题”，但是许久不碰算法的我需要一门课来回顾一下。我就上了这门各大论坛好评如潮的课程。课程的质量确实不错，作业难度也适中，对熟悉Java和算法是很好的方式。如果对于没有刷题压力的人来说，学习这门课我非常推荐；但是，这门课不教授如何做题，它强调的是理论分析和对高阶算法的介绍。此外比较遗憾的地方就是这门课不提供证书。
![证书](/images/post/2023-01-24-learning-tracking/Algorithm.png)

### [Mathematics for Machine Learning: Linear Algebra](https://www.coursera.org/learn/linear-algebra-machine-learning/home)  (2022年上半)

去年第一学期结束前，突然好奇觉得应该补一点线性代数的知识。我期望一个提供直觉和编程练习的课程，这门课非常好的满足了我的需求，内容非常简单，同时提供的直觉十分强烈，介绍了线性代数的本质线性变换，通俗地讲即原来是一条线变换到新的坐标系还是一条线。还是很不错的课程，也是我获得的第一个证书。

![证书](/images/post/2023-01-24-learning-tracking/Linear-Algebra.png)

### [Fundamentals of Reinforcement Learning](https://www.coursera.org/learn/fundamentals-of-reinforcement-learning) (2022年末)

因为研究的需要，我开始学习强化学习有关的知识。这门课是 \<Reinforcement Learning: An Introduction\> 作者Sutton和他的学生们开的。课程时长其实非常的短，但前提是要求学生们都跟着课程一起读教材。我已经读过教材的Part1(Ch1 ~ Ch8)了，也就是tabular solution method的部分。所以省去了很多时间，看几遍视频就可以上手做作业了。作业难度适中，但帮助我更好地理解了许多算法。此外，看视频的同时我才意识到有许多隐藏在书本文字之下的逻辑和一些算法的实现细节，我猜测也许作者是为了推销课程故意把一些重要的部分放在课程里面了，我也只有上了课之后才了解到其中的奥妙。还是很推荐的。此外，读教材的时候也用了很多金子老师的[问题](https://lecture.ecc.u-tokyo.ac.jp/~ctkaneko/rlbook/)作为参考。

![学习结果](/images/post/2023-01-24-learning-tracking/RLCourse1.png)

### [Sample-based Learning Methods](https://www.coursera.org/learn/sample-based-learning-methods) (2023年初)

这是前一门课的后续，同属Reinforcement Learning。我这周才刚刚完成所有的部分，与第一部分类似，仍然包含了许多隐藏在课本之下的逻辑，对于需要理解概念和建立直觉的入门者我而言是非常好的一门课。

## Open Course

### [IU C311/B521/A596 Programming Languages](https://cgi.luddy.indiana.edu/~c311/doku.php) (2022年末)

从大一看到王垠的博客的那时起就向往这门程序语言的入门课很久了，最近花了时间把前六课的作业做完。由于C311没有参考资料，我参考的是十年前的课程存档和[来自IIT教授Venkatesh Choppella的PoPL课程资料](https://faculty.iiit.ac.in/~venkatesh.choppella/popl/)，其中关于Lambda-calculus和CPS变换的部分笔记十分的精彩。前几个月我曾发邮件询问是否有课程前半部分的资料，遗憾的是前半部分不属于Choppella教授的内容，所以没有公开。（似乎私人邮件内容是可以公开的😌)

![回信](/images/post/2023-01-24-learning-tracking/Reply.png)

### [MIT Distributed Systems](https://pdos.csail.mit.edu/6.824/index.html) (2022年末)

这个是MIT分布式课程，我只做了第一课；实验部分量比较大，但要求老老实实看视频上课，不然做的时候会因为缺乏关键信息然后做的超级累。我不太喜欢几个小时几个小时的视频砸进去，所以暂时没有继续做了。
